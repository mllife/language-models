{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCmjcOc9yEtQ"
      },
      "source": [
        "# Speech-to-Text | Get transcription with speakers (OpenAI Whisper + NeMo Speaker Diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Author: [Pierre GUILLOU]()\n",
        "- Full Credit: this notebook is just an update of the notebook [Whisper_Transcription_%2B_NeMo_Diarization.ipynb](https://github.com/MahmoudAshraf97/whisper-diarization/blob/main/Whisper_Transcription_%2B_NeMo_Diarization.ipynb) of [Mahmoud Ashraf](https://github.com/MahmoudAshraf97) (all texts were kept)\n",
        "- Date: 07/12/2023\n",
        "- Blog post: [Speech-to-Text | Get transcription WITH SPEAKERS from large audio file in any language (OpenAI Whisper + NeMo Speaker Diarization)](https://medium.com/@pierre_guillou/speech-to-text-get-transcription-with-speakers-from-large-audio-file-in-any-language-openai-8da2312f1617)"
      ],
      "metadata": {
        "id": "Jz8FNiwFs8t2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "OKwioL2-uXYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[source: from [Mahmoud Ashraf](https://github.com/MahmoudAshraf97)] This notebook combines Whisper ASR capabilities with Voice Activity Detection (VAD) and Speaker Embedding to identify the speaker for each sentence in the transcription generated by Whisper. First, the vocals are extracted from the audio to increase the speaker embedding accuracy, then the transcription is generated using Whisper, then the timestamps are corrected and aligned using WhisperX to help minimize diarization error due to time shift. The audio is then passed into MarbleNet for VAD and segmentation to exclude silences, TitaNet is then used to extract speaker embeddings to identify the speaker for each segment, the result is then associated with the timestamps generated by WhisperX to detect the speaker for each word based on timestamps and then realigned using punctuation models to compensate for minor time shifts."
      ],
      "metadata": {
        "id": "wgx3_w9fucEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WARNING"
      ],
      "metadata": {
        "id": "3qcWPp6wvAJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This notebook runs on (free) Google Colab.\n",
        "- It was tested on GPU T4."
      ],
      "metadata": {
        "id": "3laKzNa2vDsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "bLs16T49rZbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check there is at least a T4 GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOB8S4ASuxq-",
        "outputId": "c5e5de7f-8612-4298-d1c9-61939cff7712"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  7 20:24:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies"
      ],
      "metadata": {
        "id": "3SXrfNF3vzaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the libraries, it is necessary to restart the runtime (session) in Google Colab."
      ],
      "metadata": {
        "id": "b3AAqk7Mvo40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tn1c-CoDv2kw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/m-bain/whisperX.git@a5dca2cc65b1a37f32a347e574b2c56af3a7434a\n",
        "!pip install --no-build-isolation nemo_toolkit[asr]==1.21.0\n",
        "!pip install git+https://github.com/facebookresearch/demucs#egg=demucs\n",
        "!pip install deepmultilingualpunctuation\n",
        "!pip install wget pydub\n",
        "# !pip install --force-reinstall torch torchaudio torchvision\n",
        "# !pip uninstall -y nvidia-cudnn-cu12\n",
        "!pip install numba==0.58.0\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESTART the runtime now!**"
      ],
      "metadata": {
        "id": "VQ8dccH7vsyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "YvJ3VVUOv14T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YzhncHP0ytbQ",
        "outputId": "de90b526-e5f9-4a3a-9d80-68a2f253026f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "[NeMo W 2023-12-07 20:34:29 transformer_bpe_models:59] Could not import NeMo NLP collection which is required for speech translation model.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import wget\n",
        "from omegaconf import OmegaConf\n",
        "import json\n",
        "import shutil\n",
        "from faster_whisper import WhisperModel\n",
        "import whisperx\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import re\n",
        "import logging\n",
        "import nltk\n",
        "from whisperx.alignment import DEFAULT_ALIGN_MODELS_HF, DEFAULT_ALIGN_MODELS_TORCH\n",
        "from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE\n",
        "\n",
        "import unidecode\n",
        "from unidecode import unidecode\n",
        "import pathlib\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsUt3SwyhjD"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Se6Hc7CZygxu"
      },
      "outputs": [],
      "source": [
        "punct_model_langs = [\n",
        "    \"en\",\n",
        "    \"fr\",\n",
        "    \"de\",\n",
        "    \"es\",\n",
        "    \"it\",\n",
        "    \"nl\",\n",
        "    \"pt\",\n",
        "    \"bg\",\n",
        "    \"pl\",\n",
        "    \"cs\",\n",
        "    \"sk\",\n",
        "    \"sl\",\n",
        "]\n",
        "wav2vec2_langs = list(DEFAULT_ALIGN_MODELS_TORCH.keys()) + list(\n",
        "    DEFAULT_ALIGN_MODELS_HF.keys()\n",
        ")\n",
        "\n",
        "whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n",
        "    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",
        ")\n",
        "\n",
        "\n",
        "def create_config(output_dir, DOMAIN_TYPE = \"telephonic\"):\n",
        "    # DOMAIN_TYPE: can be meeting, telephonic, or general based on domain type of the audio file\n",
        "    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
        "    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
        "    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n",
        "    if not os.path.exists(MODEL_CONFIG):\n",
        "        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n",
        "\n",
        "    config = OmegaConf.load(MODEL_CONFIG)\n",
        "\n",
        "    data_dir = os.path.join(output_dir, \"data\")\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    meta = {\n",
        "        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n",
        "        \"offset\": 0,\n",
        "        \"duration\": None,\n",
        "        \"label\": \"infer\",\n",
        "        \"text\": \"-\",\n",
        "        \"rttm_filepath\": None,\n",
        "        \"uem_filepath\": None,\n",
        "    }\n",
        "    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
        "        json.dump(meta, fp)\n",
        "        fp.write(\"\\n\")\n",
        "\n",
        "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
        "    pretrained_speaker_model = \"titanet_large\"\n",
        "    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n",
        "    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
        "    config.diarizer.out_dir = (\n",
        "        output_dir  # Directory to store intermediate files and prediction outputs\n",
        "    )\n",
        "\n",
        "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
        "    config.diarizer.oracle_vad = (\n",
        "        False  # compute VAD provided with model_path to vad config\n",
        "    )\n",
        "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
        "\n",
        "    # Here, we use our in-house pretrained NeMo VAD model\n",
        "    config.diarizer.vad.model_path = pretrained_vad\n",
        "    config.diarizer.vad.parameters.onset = 0.8\n",
        "    config.diarizer.vad.parameters.offset = 0.6\n",
        "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
        "    config.diarizer.msdd_model.model_path = (\n",
        "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
        "    )\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def get_word_ts_anchor(s, e, option=\"start\"):\n",
        "    if option == \"end\":\n",
        "        return e\n",
        "    elif option == \"mid\":\n",
        "        return (s + e) / 2\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
        "    s, e, sp = spk_ts[0]\n",
        "    wrd_pos, turn_idx = 0, 0\n",
        "    wrd_spk_mapping = []\n",
        "    for wrd_dict in wrd_ts:\n",
        "        ws, we, wrd = (\n",
        "            int(wrd_dict[\"start\"] * 1000),\n",
        "            int(wrd_dict[\"end\"] * 1000),\n",
        "            wrd_dict[\"word\"],\n",
        "        )\n",
        "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
        "        while wrd_pos > float(e):\n",
        "            turn_idx += 1\n",
        "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
        "            s, e, sp = spk_ts[turn_idx]\n",
        "            if turn_idx == len(spk_ts) - 1:\n",
        "                e = get_word_ts_anchor(ws, we, option=\"end\")\n",
        "        wrd_spk_mapping.append(\n",
        "            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
        "        )\n",
        "    return wrd_spk_mapping\n",
        "\n",
        "\n",
        "sentence_ending_punctuations = \".?!\"\n",
        "\n",
        "\n",
        "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    left_idx = word_idx\n",
        "    while (\n",
        "        left_idx > 0\n",
        "        and word_idx - left_idx < max_words\n",
        "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
        "        and not is_word_sentence_end(left_idx - 1)\n",
        "    ):\n",
        "        left_idx -= 1\n",
        "\n",
        "    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
        "\n",
        "\n",
        "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    right_idx = word_idx\n",
        "    while (\n",
        "        right_idx < len(word_list)\n",
        "        and right_idx - word_idx < max_words\n",
        "        and not is_word_sentence_end(right_idx)\n",
        "    ):\n",
        "        right_idx += 1\n",
        "\n",
        "    return (\n",
        "        right_idx\n",
        "        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "\n",
        "def get_realigned_ws_mapping_with_punctuation(\n",
        "    word_speaker_mapping, max_words_in_sentence=50\n",
        "):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0\n",
        "        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    wsp_len = len(word_speaker_mapping)\n",
        "\n",
        "    words_list, speaker_list = [], []\n",
        "    for k, line_dict in enumerate(word_speaker_mapping):\n",
        "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
        "        words_list.append(word)\n",
        "        speaker_list.append(speaker)\n",
        "\n",
        "    k = 0\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k]\n",
        "        if (\n",
        "            k < wsp_len - 1\n",
        "            and speaker_list[k] != speaker_list[k + 1]\n",
        "            and not is_word_sentence_end(k)\n",
        "        ):\n",
        "            left_idx = get_first_word_idx_of_sentence(\n",
        "                k, words_list, speaker_list, max_words_in_sentence\n",
        "            )\n",
        "            right_idx = (\n",
        "                get_last_word_idx_of_sentence(\n",
        "                    k, words_list, max_words_in_sentence - k + left_idx - 1\n",
        "                )\n",
        "                if left_idx > -1\n",
        "                else -1\n",
        "            )\n",
        "            if min(left_idx, right_idx) == -1:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
        "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
        "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
        "                right_idx - left_idx + 1\n",
        "            )\n",
        "            k = right_idx\n",
        "\n",
        "        k += 1\n",
        "\n",
        "    k, realigned_list = 0, []\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k].copy()\n",
        "        line_dict[\"speaker\"] = speaker_list[k]\n",
        "        realigned_list.append(line_dict)\n",
        "        k += 1\n",
        "\n",
        "    return realigned_list\n",
        "\n",
        "\n",
        "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
        "    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n",
        "    s, e, spk = spk_ts[0]\n",
        "    prev_spk = spk\n",
        "\n",
        "    snts = []\n",
        "    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n",
        "\n",
        "    for wrd_dict in word_speaker_mapping:\n",
        "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
        "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
        "        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n",
        "            snts.append(snt)\n",
        "            snt = {\n",
        "                \"speaker\": f\"Speaker {spk}\",\n",
        "                \"start_time\": s,\n",
        "                \"end_time\": e,\n",
        "                \"text\": \"\",\n",
        "            }\n",
        "        else:\n",
        "            snt[\"end_time\"] = e\n",
        "        snt[\"text\"] += wrd + \" \"\n",
        "        prev_spk = spk\n",
        "\n",
        "    snts.append(snt)\n",
        "    return snts\n",
        "\n",
        "\n",
        "def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n",
        "    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n",
        "    f.write(f\"{previous_speaker}: \")\n",
        "\n",
        "    for sentence_dict in sentences_speaker_mapping:\n",
        "        speaker = sentence_dict[\"speaker\"]\n",
        "        sentence = sentence_dict[\"text\"]\n",
        "\n",
        "        # If this speaker doesn't match the previous one, start a new paragraph\n",
        "        if speaker != previous_speaker:\n",
        "            f.write(f\"\\n\\n{speaker}: \")\n",
        "            previous_speaker = speaker\n",
        "\n",
        "        # No matter what, write the current sentence\n",
        "        f.write(sentence + \" \")\n",
        "\n",
        "\n",
        "def format_timestamp(\n",
        "    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n",
        "):\n",
        "    assert milliseconds >= 0, \"non-negative timestamp expected\"\n",
        "\n",
        "    hours = milliseconds // 3_600_000\n",
        "    milliseconds -= hours * 3_600_000\n",
        "\n",
        "    minutes = milliseconds // 60_000\n",
        "    milliseconds -= minutes * 60_000\n",
        "\n",
        "    seconds = milliseconds // 1_000\n",
        "    milliseconds -= seconds * 1_000\n",
        "\n",
        "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
        "    return (\n",
        "        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def write_srt(transcript, file):\n",
        "    \"\"\"\n",
        "    Write a transcript to a file in SRT format.\n",
        "\n",
        "    \"\"\"\n",
        "    for i, segment in enumerate(transcript, start=1):\n",
        "        # write srt lines\n",
        "        print(\n",
        "            f\"{i}\\n\"\n",
        "            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n",
        "            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n",
        "            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n",
        "            file=file,\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def find_numeral_symbol_tokens(tokenizer):\n",
        "    numeral_symbol_tokens = [\n",
        "        -1,\n",
        "    ]\n",
        "    for token, token_id in tokenizer.get_vocab().items():\n",
        "        has_numeral_symbol = any(c in \"0123456789%$£\" for c in token)\n",
        "        if has_numeral_symbol:\n",
        "            numeral_symbol_tokens.append(token_id)\n",
        "    return numeral_symbol_tokens\n",
        "\n",
        "\n",
        "def _get_next_start_timestamp(word_timestamps, current_word_index):\n",
        "    # if current word is the last word\n",
        "    if current_word_index == len(word_timestamps) - 1:\n",
        "        return word_timestamps[current_word_index][\"start\"]\n",
        "\n",
        "    next_word_index = current_word_index + 1\n",
        "    while current_word_index < len(word_timestamps) - 1:\n",
        "        if word_timestamps[next_word_index].get(\"start\") is None:\n",
        "            # if next word doesn't have a start timestamp\n",
        "            # merge it with the current word and delete it\n",
        "            word_timestamps[current_word_index][\"word\"] += (\n",
        "                \" \" + word_timestamps[next_word_index][\"word\"]\n",
        "            )\n",
        "\n",
        "            word_timestamps[next_word_index][\"word\"] = None\n",
        "            next_word_index += 1\n",
        "\n",
        "        else:\n",
        "            return word_timestamps[next_word_index][\"start\"]\n",
        "\n",
        "\n",
        "def filter_missing_timestamps(word_timestamps):\n",
        "    # handle the first and last word\n",
        "    if word_timestamps[0].get(\"start\") is None:\n",
        "        word_timestamps[0][\"start\"] = 0\n",
        "        word_timestamps[0][\"end\"] = _get_next_start_timestamp(word_timestamps, 0)\n",
        "\n",
        "    result = [\n",
        "        word_timestamps[0],\n",
        "    ]\n",
        "\n",
        "    for i, ws in enumerate(word_timestamps[1:], start=1):\n",
        "        # if ws doesn't have a start and end\n",
        "        # use the previous end as start and next start as end\n",
        "        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n",
        "            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n",
        "            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i)\n",
        "\n",
        "        if ws[\"word\"] is not None:\n",
        "            result.append(ws)\n",
        "    return result\n",
        "\n",
        "\n",
        "def cleanup(path: str):\n",
        "    \"\"\"path could either be relative or absolute.\"\"\"\n",
        "    # check if file or directory exists\n",
        "    if os.path.isfile(path) or os.path.islink(path):\n",
        "        # remove file\n",
        "        os.remove(path)\n",
        "    elif os.path.isdir(path):\n",
        "        # remove directory and all its content\n",
        "        shutil.rmtree(path)\n",
        "    else:\n",
        "        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n",
        "\n",
        "\n",
        "def process_language_arg(language: str, model_name: str):\n",
        "    \"\"\"\n",
        "    Process the language argument to make sure it's valid and convert language names to language codes.\n",
        "    \"\"\"\n",
        "    if language is not None:\n",
        "        language = language.lower()\n",
        "    if language not in LANGUAGES:\n",
        "        if language in TO_LANGUAGE_CODE:\n",
        "            language = TO_LANGUAGE_CODE[language]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported language: {language}\")\n",
        "\n",
        "    if model_name.endswith(\".en\") and language != \"en\":\n",
        "        if language is not None:\n",
        "            logging.warning(\n",
        "                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n",
        "            )\n",
        "        language = \"en\"\n",
        "    return language\n",
        "\n",
        "\n",
        "def transcribe(\n",
        "    audio_file: str,\n",
        "    language: str,\n",
        "    model_name: str,\n",
        "    compute_dtype: str,\n",
        "    suppress_numerals: bool,\n",
        "    device: str,\n",
        "):\n",
        "    from faster_whisper import WhisperModel\n",
        "    from helpers import find_numeral_symbol_tokens, wav2vec2_langs\n",
        "\n",
        "    # Faster Whisper non-batched\n",
        "    # Run on GPU with FP16\n",
        "    whisper_model = WhisperModel(model_name, device=device, compute_type=compute_dtype)\n",
        "\n",
        "    # or run on GPU with INT8\n",
        "    # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
        "    # or run on CPU with INT8\n",
        "    # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
        "\n",
        "    if suppress_numerals:\n",
        "        numeral_symbol_tokens = find_numeral_symbol_tokens(whisper_model.hf_tokenizer)\n",
        "    else:\n",
        "        numeral_symbol_tokens = None\n",
        "\n",
        "    if language is not None and language in wav2vec2_langs:\n",
        "        word_timestamps = False\n",
        "    else:\n",
        "        word_timestamps = True\n",
        "\n",
        "    segments, info = whisper_model.transcribe(\n",
        "        audio_file,\n",
        "        language=language,\n",
        "        beam_size=5,\n",
        "        word_timestamps=word_timestamps,  # TODO: disable this if the language is supported by wav2vec2\n",
        "        suppress_tokens=numeral_symbol_tokens,\n",
        "        vad_filter=True,\n",
        "    )\n",
        "    whisper_results = []\n",
        "    for segment in segments:\n",
        "        whisper_results.append(segment._asdict())\n",
        "    # clear gpu vram\n",
        "    del whisper_model\n",
        "    torch.cuda.empty_cache()\n",
        "    return whisper_results, language\n",
        "\n",
        "\n",
        "def transcribe_batched(\n",
        "    audio_file: str,\n",
        "    language: str,\n",
        "    batch_size: int,\n",
        "    model_name: str,\n",
        "    compute_dtype: str,\n",
        "    suppress_numerals: bool,\n",
        "    device: str,\n",
        "):\n",
        "    import whisperx\n",
        "\n",
        "    # Faster Whisper batched\n",
        "    whisper_model = whisperx.load_model(\n",
        "        model_name,\n",
        "        device,\n",
        "        compute_type=compute_dtype,\n",
        "        asr_options={\"suppress_numerals\": suppress_numerals},\n",
        "    )\n",
        "    audio = whisperx.load_audio(audio_file)\n",
        "    result = whisper_model.transcribe(audio, language=language, batch_size=batch_size)\n",
        "    del whisper_model\n",
        "    torch.cuda.empty_cache()\n",
        "    return result[\"segments\"], result[\"language\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no space, punctuation, accent in lower string\n",
        "def cleanString(string):\n",
        "    cleanString = unidecode(string)\n",
        "    # cleanString = re.sub('\\W+','_', cleanString)\n",
        "    cleanString = re.sub(r'[^\\w\\s]','',cleanString)\n",
        "    cleanString = cleanString.replace(\" \", \"_\")\n",
        "    return cleanString.lower()\n",
        "\n",
        "# rename audio filename to get name without accent, no space, in lower case\n",
        "def rename_file(filepath):\n",
        "    suffix = Path(filepath).suffix\n",
        "    if str(Path(filepath).parent) != \".\":\n",
        "        new_filepath = str(Path(filepath).parent) + cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "    else:\n",
        "        new_filepath = cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "    os.rename(filepath, new_filepath)\n",
        "    return new_filepath"
      ],
      "metadata": {
        "id": "CxDrdPzKD4_s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7qWQb--1Xcw"
      },
      "source": [
        "## Setup options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ONlFrSnD0FOp"
      },
      "outputs": [],
      "source": [
        "# Name of the audio file\n",
        "audio_path = \"andrew_ng_ai_regulation_education_and_where_we_are_headed_for_healthcare_and_beyond.mp3\"\n",
        "\n",
        "# rename audio filename if necessary to get string without accent, space, in lower case\n",
        "audio_path = rename_file(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Option) Whether to enable music removal from speech, helps increase diarization quality but uses alot of ram\n",
        "enable_stemming = False\n",
        "\n",
        "# (choose from 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large')\n",
        "# whisper_model_name = \"large-v2\"\n",
        "whisper_model_name = \"large-v3\"\n",
        "\n",
        "# replaces numerical digits with their pronounciation, increases diarization accuracy\n",
        "suppress_numerals = True\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "language = None  # autodetect language\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "-JTNHNtbnzm_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check device\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9LlSGeKy8M9s",
        "outputId": "862d0ba0-41bb-480f-955d-2953891f4116"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-cY1ZEy2KVI"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZS4xXmE2NGP"
      },
      "source": [
        "## (Option) Separating music from speech using Demucs\n",
        "\n",
        "---\n",
        "\n",
        "By isolating the vocals from the rest of the audio, it becomes easier to identify and track individual speakers based on the spectral and temporal characteristics of their speech signals. Source separation is just one of many techniques that can be used as a preprocessing step to help improve the accuracy and reliability of the overall diarization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HKcgQUrAzsJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cedf62-cb38-4497-a80c-06c01bd9e269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 7.87 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if enable_stemming:\n",
        "    # Isolate vocals from the rest of the audio\n",
        "\n",
        "    return_code = os.system(\n",
        "        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n",
        "    )\n",
        "\n",
        "    if return_code != 0:\n",
        "        logging.warning(\"Source splitting failed, using original audio file.\")\n",
        "        vocal_target = audio_path\n",
        "    else:\n",
        "        vocal_target = os.path.join(\n",
        "            \"temp_outputs\",\n",
        "            \"htdemucs\",\n",
        "            os.path.splitext(os.path.basename(audio_path))[0],\n",
        "            \"vocals.wav\",\n",
        "        )\n",
        "else:\n",
        "    vocal_target = audio_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYg9VWb22Tz8"
      },
      "source": [
        "## Transcriping audio using Whisper and realligning timestamps using Wav2Vec2\n",
        "---\n",
        "This code uses two different open-source models to transcribe speech and perform forced alignment on the resulting transcription.\n",
        "\n",
        "The first model is called OpenAI Whisper, which is a speech recognition model that can transcribe speech with high accuracy. The code loads the whisper model and uses it to transcribe the vocal_target file.\n",
        "\n",
        "The output of the transcription process is a set of text segments with corresponding timestamps indicating when each segment was spoken.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5-VKFn530oTl",
        "outputId": "08b74c7d-dcaa-4b29-bb79-2453142f6c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "53e85b0ff03348da9b5161c7fba16f13",
            "420afc03ebf8472d9792c065603cec8c",
            "ee259261eb3446429eade012600148ec",
            "3b4ed23d4a66441f98e9a268562b7acd",
            "0a5d35ea6edc40fe853029d80d9068be",
            "6252680196da4e61aac4bc7e3b81785c",
            "dc8f8181f8854a2c9ba892ef5e06b992",
            "9a47a284a46c481686b5f29e66d62df3",
            "9263d61d69394e409a898059eb02b783",
            "0597dcece28142f8a3cf94c0bee59036",
            "eac30a39471c4d1e932bfee0078e2367",
            "faac16f3704f41ca822793f113b13d74",
            "efa0029440a94683bcf5b29d0676bd1e",
            "3f664856b7904acdbae95d665e9116cd",
            "09373e215d43496482703f235070aee5",
            "8c5546be3454475b9018bf1668990bfb",
            "429c40b6d7e44b659f6c33d9be018e61",
            "12117084fba24e27818b9cccfc872337",
            "2ccce7d3919943bc808d73b4c6e41915",
            "1fea0021462d4502b6dd98f2641f36d3",
            "8ee16ff006db416584674627bbda15a8",
            "4ed477e1776d47e4bf1c0898e9025897",
            "d683f557775b4a22bd6a62e88e66b053",
            "6e9c4a0205ae47299ee21362bd5c2301",
            "b6a93f7644524f9f8a425535e78177a8",
            "8b143daae9ef445ea0ced881628c76c1",
            "dc72c90bb09146a5a26afd314a23b725",
            "0eda71f699b842c98833b8fb049bcc86",
            "664aee83839e4688b7aebe19e10243b4",
            "83ef5f2d81fe45e291722e1e538be3c7",
            "17af76389c754e07a266bc7f00c92c97",
            "5ec8460a5f684440acd8f9c35e813b7d",
            "e4b83fd23b874960be9ae781d0e1a42c",
            "495ff045a1834bb78f10a6fabdcc77f2",
            "81350efd7281432396e766c2bc2f37b4",
            "8aa703a8e664468fa440d9d595f27650",
            "02253b1512c24944bf8533e9fbd818f4",
            "d3e0352d59204449b98ce0b684775ff2",
            "d0226d3205b341eb8d419f2627e3ae81",
            "ff2edd67f2e5405b902d824faf03e84c",
            "46010e09947944baace0465da4b62c91",
            "cc543b64df4d44f2a9f8e6d7cb6e8f24",
            "14de5b420e8d4d248ddd7269e1f6b9be",
            "fc23792a5ecb469e873888434602365e",
            "195e69c5ea3047589ff8fed9068269d7",
            "e0045b89dfa941a9b99f22e55cf21415",
            "ce46b162b882488c955edd8fc8162aee",
            "47d89beb2240494e9645ba1330e0bcec",
            "587b2463637b4558b268d97bc4a3b2f4",
            "c13d06e5bbb44bcc9805b7baa935e8d7",
            "2619c73df9f9441390db86a2f38cecde",
            "de635fed43934fdabc39108e0d697e63",
            "cccb461e4e024f60adcb9377ce2dc774",
            "8af741d8baa04a35979cdcf6a20a4c73",
            "334d17ca36ce474aa617d5a95f501fb7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53e85b0ff03348da9b5161c7fba16f13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faac16f3704f41ca822793f113b13d74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d683f557775b4a22bd6a62e88e66b053"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "495ff045a1834bb78f10a6fabdcc77f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "195e69c5ea3047589ff8fed9068269d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 16.9M/16.9M [00:01<00:00, 11.8MiB/s]\n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: en (1.00) in first 30s of audio...\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "CPU times: user 1min 18s, sys: 11.9 s, total: 1min 30s\n",
            "Wall time: 2min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if device == \"cuda\": compute_type = \"float16\"\n",
        "# or run on GPU with INT8\n",
        "# compute_type = \"int8_float16\"\n",
        "# or run on CPU with INT8\n",
        "else: compute_type = \"int8\"\n",
        "\n",
        "if batch_size != 0:\n",
        "    whisper_results, language = transcribe_batched(\n",
        "        vocal_target,\n",
        "        language,\n",
        "        batch_size,\n",
        "        whisper_model_name,\n",
        "        compute_type,\n",
        "        suppress_numerals,\n",
        "        device,\n",
        "    )\n",
        "else:\n",
        "    whisper_results, language = transcribe(\n",
        "        vocal_target,\n",
        "        language,\n",
        "        whisper_model_name,\n",
        "        compute_type,\n",
        "        suppress_numerals,\n",
        "        device,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRJFzumCxd-I"
      },
      "source": [
        "## Aligning the transcription with the original audio using Wav2Vec2\n",
        "---\n",
        "The second model used is called wav2vec2, which is a large-scale neural network that is designed to learn representations of speech that are useful for a variety of speech processing tasks, including speech recognition and alignment.\n",
        "\n",
        "The code loads the wav2vec2 alignment model and uses it to align the transcription segments with the original audio signal contained in the vocal_target file. This process involves finding the exact timestamps in the audio signal where each segment was spoken and aligning the text accordingly.\n",
        "\n",
        "By combining the outputs of the two models, the code produces a fully aligned transcription of the speech contained in the vocal_target file. This aligned transcription can be useful for a variety of speech processing tasks, such as speaker diarization, sentiment analysis, and language identification.\n",
        "\n",
        "If there's no Wav2Vec2 model available for your language, word timestamps generated by whisper will be used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1O15cfnDxd-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea72fb9-87c7-4b2c-f350-0cb0cdf732ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n",
            "100%|██████████| 360M/360M [00:06<00:00, 58.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.9 s, sys: 1.37 s, total: 34.2 s\n",
            "Wall time: 44.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if language in wav2vec2_langs:\n",
        "    device = \"cuda\"\n",
        "    alignment_model, metadata = whisperx.load_align_model(\n",
        "        language_code=language, device=device\n",
        "    )\n",
        "    result_aligned = whisperx.align(\n",
        "        whisper_results, alignment_model, metadata, vocal_target, device\n",
        "    )\n",
        "    word_timestamps = filter_missing_timestamps(result_aligned[\"word_segments\"])\n",
        "\n",
        "    # clear gpu vram\n",
        "    del alignment_model\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    assert batch_size == 0, (  # TODO: add a better check for word timestamps existence\n",
        "        f\"Unsupported language: {language}, use --batch_size to 0\"\n",
        "        \" to generate word timestamps using whisper directly and fix this error.\"\n",
        "    )\n",
        "    word_timestamps = []\n",
        "    for segment in whisper_results:\n",
        "        for word in segment[\"words\"]:\n",
        "            word_timestamps.append({\"word\": word[2], \"start\": word[0], \"end\": word[1]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EEaJPsQ21Rx"
      },
      "source": [
        "## Convert audio to mono for NeMo combatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RG0kNnGMxd-I",
        "outputId": "e968476e-3c95-42d6-b158-1092e1b7bccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.38 s, sys: 1.12 s, total: 2.5 s\n",
            "Wall time: 6.89 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/temp_outputs/mono_file.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "%%time\n",
        "sound = AudioSegment.from_file(vocal_target).set_channels(1)\n",
        "ROOT = os.getcwd()\n",
        "temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
        "os.makedirs(temp_path, exist_ok=True)\n",
        "sound.export(os.path.join(temp_path, \"mono_file.wav\"), format=\"wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gkViCf2-CV"
      },
      "source": [
        "## Speaker Diarization using NeMo MSDD Model\n",
        "---\n",
        "This code uses a model called Nvidia NeMo MSDD (Multi-scale Diarization Decoder) to perform speaker diarization on an audio signal. Speaker diarization is the process of separating an audio signal into different segments based on who is speaking at any given time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C7jIpBCH02RL",
        "outputId": "d8c7c5a0-8005-4524-f173-f6688a80ac31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:37:32 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2023-12-07 20:37:32 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/diar_msdd_telephonic/versions/1.0.1/files/diar_msdd_telephonic.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2023-12-07 20:37:35 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-12-07 20:37:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2023-12-07 20:37:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2023-12-07 20:37:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:37:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-12-07 20:37:37 features:289] PADDING: 16\n",
            "[NeMo I 2023-12-07 20:37:38 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2023-12-07 20:37:38 features:289] PADDING: 16\n",
            "[NeMo I 2023-12-07 20:37:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2023-12-07 20:37:39 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2023-12-07 20:37:39 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-12-07 20:37:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-12-07 20:37:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2023-12-07 20:37:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:37:39 features:289] PADDING: 16\n",
            "[NeMo I 2023-12-07 20:37:39 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2023-12-07 20:37:39 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2023-12-07 20:37:39 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2023-12-07 20:37:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-12-07 20:37:39 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:10<00:00, 10.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:37:50 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2023-12-07 20:37:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:37:50 collections:302] Dataset loaded with 39 items, total duration of  0.54 hours.\n",
            "[NeMo I 2023-12-07 20:37:50 collections:304] # 39 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 39/39 [00:10<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:01 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:21 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2023-12-07 20:38:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-12-07 20:38:23 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:38:23 collections:302] Dataset loaded with 1934 items, total duration of  0.68 hours.\n",
            "[NeMo I 2023-12-07 20:38:23 collections:304] # 1934 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 31/31 [00:05<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2023-12-07 20:38:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2023-12-07 20:38:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-12-07 20:38:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:38:29 collections:302] Dataset loaded with 2355 items, total duration of  0.71 hours.\n",
            "[NeMo I 2023-12-07 20:38:29 collections:304] # 2355 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 37/37 [00:06<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:36 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2023-12-07 20:38:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2023-12-07 20:38:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-12-07 20:38:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:38:36 collections:302] Dataset loaded with 2922 items, total duration of  0.73 hours.\n",
            "[NeMo I 2023-12-07 20:38:36 collections:304] # 2922 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 46/46 [00:07<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2023-12-07 20:38:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2023-12-07 20:38:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-12-07 20:38:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:38:44 collections:302] Dataset loaded with 3923 items, total duration of  0.76 hours.\n",
            "[NeMo I 2023-12-07 20:38:44 collections:304] # 3923 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 62/62 [00:08<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:38:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2023-12-07 20:38:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2023-12-07 20:38:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2023-12-07 20:38:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2023-12-07 20:38:53 collections:302] Dataset loaded with 5981 items, total duration of  0.80 hours.\n",
            "[NeMo I 2023-12-07 20:38:53 collections:304] # 5981 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 94/94 [00:11<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:06<00:00,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:14 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2023-12-07 20:39:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:16 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2023-12-07 20:39:16 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2023-12-07 20:39:16 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2023-12-07 20:39:16 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2023-12-07 20:39:16 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2023-12-07 20:39:16 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2023-12-07 20:39:17 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2023-12-07 20:39:17 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:18 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2023-12-07 20:39:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2023-12-07 20:39:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2023-12-07 20:39:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-12-07 20:39:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-12-07 20:39:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-12-07 20:39:19 msdd_models:1431]   \n",
            "    \n",
            "CPU times: user 1min 33s, sys: 5.08 s, total: 1min 38s\n",
            "Wall time: 1min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Initialize NeMo MSDD diarization model\n",
        "# DOMAIN_TYPE: can be meeting, telephonic, or general based on domain type of the audio file\n",
        "msdd_model = NeuralDiarizer(cfg=create_config(temp_path, DOMAIN_TYPE=\"telephonic\")).to(\"cuda\")\n",
        "msdd_model.diarize()\n",
        "\n",
        "del msdd_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmkZYaDAEOAg"
      },
      "source": [
        "## Mapping Spekers to Sentences According to Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E65LUGQe02zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d188c301-fc4b-4f1d-c349-36f44987347f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.5 ms, sys: 0 ns, total: 11.5 ms\n",
            "Wall time: 11.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Reading timestamps <> Speaker Labels mapping\n",
        "\n",
        "speaker_ts = []\n",
        "with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line_list = line.split(\" \")\n",
        "        s = int(float(line_list[5]) * 1000)\n",
        "        e = s + int(float(line_list[8]) * 1000)\n",
        "        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
        "\n",
        "wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ruxc8S1EXtW"
      },
      "source": [
        "## Realligning Speech segments using Punctuation\n",
        "---\n",
        "\n",
        "This code provides a method for disambiguating speaker labels in cases where a sentence is split between two different speakers. It uses punctuation markings to determine the dominant speaker for each sentence in the transcription.\n",
        "\n",
        "```\n",
        "Speaker A: It's got to come from somewhere else. Yeah, that one's also fun because you know the lows are\n",
        "Speaker B: going to suck, right? So it's actually it hits you on both sides.\n",
        "```\n",
        "\n",
        "For example, if a sentence is split between two speakers, the code takes the mode of speaker labels for each word in the sentence, and uses that speaker label for the whole sentence. This can help to improve the accuracy of speaker diarization, especially in cases where the Whisper model may not take fine utterances like \"hmm\" and \"yeah\" into account, but the Diarization Model (Nemo) may include them, leading to inconsistent results.\n",
        "\n",
        "The code also handles cases where one speaker is giving a monologue while other speakers are making occasional comments in the background. It ignores the comments and assigns the entire monologue to the speaker who is speaking the majority of the time. This provides a robust and reliable method for realigning speech segments to their respective speakers based on punctuation in the transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pgfC5hA41BXu",
        "outputId": "b9d6c650-7fe2-4e05-a7ba-e390f9f4eef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "159db77aa273471b9041f891a7a04d8d",
            "2f183a47452b48bda6df212d1a65bdd0",
            "27495cbba22545f59f7b10e9e6adc9a2",
            "6355e03b327c4097b0d1710e282efdf8",
            "bf535d85837e41d48a6037393d30c08a",
            "177396d768b94546b80a6668903c287d",
            "ab2f91b40ef04139910fc7dd8e05fe2a",
            "affffa7df2e545de8d6d6712636ed879",
            "ed86c68369f94014b48323e05db9ea3a",
            "27bd8c8ac9bc4b3985ba2b4cd4b28cce",
            "bd68c1380f0f49cb82797b8725ea9dac",
            "9fabcefb3c8b4e4eabc0176301f2599f",
            "8f2ba7022ffd4277a2bd4d9456d71bea",
            "f3f6027b899c4a17b419fcfe9b4ed801",
            "0c65546f9fcd49bdb0f36811a2d37c27",
            "8f70bff546a7472bbb3648f5650ba804",
            "75d1522f112145398b9d88206ee8d4e0",
            "47721fc0ba4c4a86b994e7a20a4e48fd",
            "0907821d3c1943eb92c395ce7c77e9e3",
            "83696fce842f4e878b9745933a6dc165",
            "804cc5a0ef3c4421b68366db4a10e78c",
            "5108239b73b64f6f86bd5ccfef2c1244",
            "9a6d48bb1c08409781dbf43162382cc7",
            "f0a1a63ff3ac46c4b52e1aec4ac74762",
            "a3f249725a2442469531aea44b81434d",
            "c7db01a166ea443daf3f39606b02e729",
            "13d3996378074692b1511329cb85b3a3",
            "8f9ee041c81f42c6ba21f375f608b56a",
            "c5739a82e1b944018448dcfd2e368c4b",
            "d5fd8adde83b4c719fb1c3478cd6cc85",
            "02c34b95d0aa4b40b6f95a1a3dbe40ec",
            "db3c662eff0e4aaf9187fc1de065652b",
            "f1fb1ca543e84fa7b04ff6b3b25431cb",
            "3065744080cf460085e0ef24f7bc584c",
            "95fc3dc618f94330a3d7b8868d78f8dc",
            "5139df6083324c6aa92ade86aa13b62d",
            "af7f72a06c3848aca62d3348313462cf",
            "bf0176381e8145c2a4f790448dbd5d64",
            "de84fde8d23549fdbcc817692890072f",
            "bc401c5807f9461c8dee27844a6149af",
            "76f0ef4516f34824a4669a98f0742978",
            "6e8ce6c51c4f40eb80ab7f56a046b32e",
            "f5df8345a248459389a7355a1e6eeb01",
            "c99b3076ca73461cba4847e212351f12",
            "055105b482a0439cae76230451404c07",
            "353c573752304f3188ee59e61c0f8463",
            "dc9b8824acd14b52973133a53bc54b6e",
            "7f6c523584b649d1be82ce5737dd74b5",
            "5c07fc6c50394002b079fbd870b407e3",
            "671d3d7e95584867a45453b6030bfdf2",
            "2c2575f4eb474283a16f9d00f532f40e",
            "cae9646f9874472fb44d8bc427e88440",
            "747c7d6fc3bd4b0dac65c0e8893405c2",
            "bbb6b2fd0af3485189c5a2f09ac82837",
            "60dfbe775a70433dbf32d861174e5ca9"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159db77aa273471b9041f891a7a04d8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fabcefb3c8b4e4eabc0176301f2599f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/447 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a6d48bb1c08409781dbf43162382cc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3065744080cf460085e0ef24f7bc584c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "055105b482a0439cae76230451404c07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 s, sys: 2.94 s, total: 8.95 s\n",
            "Wall time: 12.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if language in punct_model_langs:\n",
        "    # restoring punctuation in the transcript to help realign the sentences\n",
        "    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "\n",
        "    words_list = list(map(lambda x: x[\"word\"], wsm))\n",
        "\n",
        "    labled_words = punct_model.predict(words_list)\n",
        "\n",
        "    ending_puncts = \".?!\"\n",
        "    model_puncts = \".,;:!?\"\n",
        "\n",
        "    # We don't want to punctuate U.S.A. with a period. Right?\n",
        "    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
        "\n",
        "    for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
        "        word = word_dict[\"word\"]\n",
        "        if (\n",
        "            word\n",
        "            and labeled_tuple[1] in ending_puncts\n",
        "            and (word[-1] not in model_puncts or is_acronym(word))\n",
        "        ):\n",
        "            word += labeled_tuple[1]\n",
        "            if word.endswith(\"..\"):\n",
        "                word = word.rstrip(\".\")\n",
        "            word_dict[\"word\"] = word\n",
        "\n",
        "else:\n",
        "    logging.warning(\n",
        "        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n",
        "    )\n",
        "\n",
        "wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
        "ssm = get_sentences_speaker_mapping(wsm, speaker_ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF2QAtLOFvwZ"
      },
      "source": [
        "## Cleanup and downloading the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kFTyKI6B1MI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d0af70-9d59-4706-cca9-e5e223040087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.22 ms, sys: 6.83 ms, total: 12.1 ms\n",
            "Wall time: 17.8 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "path_textfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.txt\"\n",
        "path_srtfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.srt\"\n",
        "\n",
        "with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "    get_speaker_aware_transcript(ssm, f)\n",
        "\n",
        "with open(path_srtfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as srt:\n",
        "    write_srt(ssm, srt)\n",
        "\n",
        "cleanup(temp_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleanup text file with speakers\n",
        "with open(path_textfile_with_speakers, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    lines = [re.sub(' +', ' ', line.strip(\"\\ufeff\").strip()) for line in lines if line != \"\\n\"]\n",
        "\n",
        "with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "    for i,line in enumerate(lines):\n",
        "        if i < len(lines) - 1: f.write(f\"{line}\\n\\n\")\n",
        "        else: f.write(f\"{line}\")"
      ],
      "metadata": {
        "id": "wzsSoy37_1Eb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download files\n",
        "from google.colab import files\n",
        "files.download(path_textfile_with_speakers)\n",
        "files.download(path_srtfile_with_speakers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eV2uNYT80g0V",
        "outputId": "69fc75ca-9b89-4ad4-9880-cdc1cb6adc3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79601fb0-5edf-4ec4-bebf-27c111efea47\", \"andrew_ng_ai_regulation_education_and_where_we_are_headed_for_healthcare_and_beyond.txt\", 27772)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_83da1389-12e6-4512-b010-9f251f2b32e7\", \"andrew_ng_ai_regulation_education_and_where_we_are_headed_for_healthcare_and_beyond.srt\", 40326)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the results"
      ],
      "metadata": {
        "id": "-YAht-GD0u8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "css = '''\n",
        "        <style>\n",
        "            .highlighted {\n",
        "                font-weight: bold;\n",
        "                font-size: 140%;\n",
        "                margin-bottom: 20px;\n",
        "                padding: 10px\n",
        "            }\n",
        "            .redstyle {\n",
        "                color:red\n",
        "            }\n",
        "            .greenstyle {\n",
        "                color:green\n",
        "            }\n",
        "        </style>\n",
        "      '''\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "for line in lines:\n",
        "    line = line.replace(\"Speaker 0\", \"<span class='redstyle'>Speaker 0</span>\")\n",
        "    line = line.replace(\"Speaker 1\", \"<span class='greenstyle'>Speaker 1</span>\")\n",
        "    display(HTML(f'{css} <p class=\"highlighted\">{line}</p>'))"
      ],
      "metadata": {
        "id": "JrqwFCoJBkna",
        "outputId": "7d83a0f9-cf50-46a6-f6cd-2cbe4ac3a607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Hello, it's Eric Topol with the Ground Truce, and I'm really delighted to have with me Andrew Ng, who is a giant in AI, who I've gotten to know over the years and have the highest regard. So, Andrew, welcome.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Thanks, Eric. It's always a pleasure to see you.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah. We've had some intersections in multiple areas of AI. The one I wanted to start with is that you've had some direct healthcare nurturing. We've had the pleasure of working with Wobot Health, particularly with Allison Darcy, where the AI chatbot has been tested in randomized trials to help people with depression and anxiety. And of course, that was a chatbot in the pre-Transformer, pre-LLM era. I wonder if you could just comment about that, as well as your outlook for current AI models in healthcare.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: So, you know, Alison Darcy is brilliant. She's been such a prolific worker for over the years. One of the exciting things for AI is that general purpose technology is not useful for one thing. And I think in healthcare and more broadly across the world, we're seeing many creative people use AI for many different applications. So I was in Singapore a couple of months ago, and I was chatting with some folks, Dean Changyup Sang and one of his doctors, Dr. Niam, about how they're using AI to read EHRs in a hospital in Singapore to try to estimate how long a patient is going to be in the hospital because of pneumonia or something. And it was actually triggering helpful conversations where a doctor would say, oh, I think this patient will be in for three days. But the AI says, nope. I'm guessing, fifteen days. and this triggers a conversation where the doctor takes a more careful look and I thought that was incredible. So all around the world, many invaders everywhere finding very creative ways to apply AI to lots of different problems. I think that's super exciting.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Oh, it's extraordinary to me. I think, you know, Jeff Hinton has thought that this is the most important application of current AI is in the healthcare and medical sphere. But, you know, I think what the range here is quite extraordinary. And one of the other things that you've been into for all these years with Coursera, starting that and all the courses, deep learning, AI, is democratization of knowledge, education, and AI. Since this is something like all patients would want to look up on whatever GPT-X about their symptoms, different than, of course, a current Google search, what's your sense about the ability to use generative AI in this way?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: I think that, um, kind of, uh, instead of seeing a doctor also, also last night, each model, right. What's up with my symptoms. I, people are definitely doing it. And there've been anecdotes of this meal, maybe saving a few people's lives even. And I think it's, uh, I think in the United States, we're privileged to have, some would say good, some would say terrible, but certainly better than many other countries' healthcare system. And I feel like a lot of the early go-to-market for AI-enabled healthcare may end up being in countries or just places with less access to doctors. There are definitely countries where you can either decide, do you want to go see if someone falls sick? You can either send your kid to a doctor or you can have your family eat for the next two weeks, pick one. So with families making these impossible decisions, I wish we could give everyone in the world access to a great doctor. And sometimes the alternatives that people face are pretty harsh. So I think any hope, even the very imperfect hope of an OOM, I know it sounds terrible, it will hallucinate, it will give bad medical advice sometimes, but is that better than no medical advice? I think there's really some tough ethical questions that are being debated around the world right now.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Those hallucinations or confabulations, won't they get better over time?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Yes. So yeah, I think, you know, technology is advanced rapidly. They still do hallucinate. They do still mix stuff up. But it turns out that I think people still have an impression of technology from six months ago, but so much has changed in the last six months. So Even in the last six months, it's actually much harder now to get an LLM, at least many of the public ones offered by large companies. It's much harder now compared to six months ago to get it to give you deliberately harmful advice. Or if you ask it for detailed instructions on how to commit a crime, Six months ago, it was actually pretty easy. So that was not good. But now it's actually pretty hard. It's not impossible. And I actually ask LLMs for strange things all the time just to test them. And yes, sometimes I can get them when I really try to do something inappropriate, but it's actually pretty difficult. But hallucination is just a different thing where LMs do make stuff up, and you definitely don't want that when it comes to medical advice. So it will be an interesting balance, I think, of when should we use web search for trusted, authoritative sources. So if I have a sprained ankle, hey, let me just find a web page from a trusted medical authority on how to deal with a sprained ankle. But there are also a lot of things where there is no one web page. that just gives me an answer and then is an alternative for generating a novel thing. that's unique to my situation. In non-healthcare cases, this has clearly been very valuable in just the healthcare, given the criticality of human health and human life. I think people are wrestling with some challenging questions, but hallucinations are slowly going down.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah, well, hopefully they'll continue to improve on that. And as you pointed out, the other guardrails will help. Now, that gets me to a little over a month ago, we were at the TED AI program and you gave the opening talk, which was very inspirational. And you basically challenged the critics of the negativism on AI. with three basically issues about amplifying our worst impulses, taking our jobs and wiping out humanity. And it was very compelling. And I hope that that will be posted soon and of course we'll link it. But can you give us a skinny of your antidote to the doomerism about AI?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: I think AI is a very beneficial technology. On average, I think it comes down to do we think the world is better off or worse off with more intelligence in it, be it human intelligence or artificial intelligence. And yes, intelligence can be used for nefarious purposes, and it has been in history. I think a lot of humanity has progress through humans getting smarter and better trained and more educated. And so I think on average, the world is better off with more intelligence in it. And as for AI wiping out humanity, I just don't get it. I've spoken with some of the people with this concern. But the arguments for how AI could wipe out humanity are so vague that they boil down to it could happen. And I can't prove it won't happen any more than I can prove a negative like that. I can't prove that radio waves being emitted from Earth won't cause aliens to find us and space aliens to wipe us out. But I'm not very alarmed about space aliens. Maybe I should be. I don't know. And I find that the harms, there are real harms that are being created by the alarmist narrative on AI. You know, one thing that was quite sad was chatting with, there are now high school students that are reluctant to enter AI because they heard it could lead to human extinction and they don't want any of that. And that's just tragic that we're causing high school students to make a decision. that's bad for themselves and bad for humanity. because of really unmerited alarms about human extinction.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: No question about that. You had, I think, a very important quote is, AI is not the problem, it's the solution during that. And I think that gets us to the recent flap, if you will, with open AI that's happened in recent days, whereby it appears to be the same tension between the techno optimists like like you and I, I would say, versus the effective altruism camp. And I wonder what your thoughts are regarding. Obviously, we don't know all the inside dynamics of this. We probably the most publicized interactions in AI that I can remember in terms of its intensity. And it's not over yet. But what were your thoughts about as this has been unfolding, which is, of course, still in process?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Yeah, honestly, a lot of my thoughts have been with all the employees of OpenAI. These are hundreds of hardworking, well-meaning people that want to build tech, make it available to others, make the world better off. And in all of the blue overnight, you know, their jobs, livelihoods and their levers to make a very positive impact to the world was disrupted for reasons that seem vague and at least from the silence of the board, I'm not aware of any good reasons for really all these wonderful people's work and then livelihoods and being disrupted. So I feel sad that that just happened to deserve. And then I feel like, you know, OpenAI is not perfect. No organization in the world is. But frankly, they've really moved AI forward. And I think a lot of people have benefited from the work of OpenAI. And I think the disruptions of that as well is also quite tragic. And this may be, we'll see if this turns out to be one of the most dramatic impacts of unwarranted doomsaying narratives causing a lot of harm to a lot of people, but we'll see what continues to emerge of the situation.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah, I mean, I think this whole concept of AGI, artificial general intelligence, and how it gets down to this fundamental assertion that we're at AGI, the digital brain, or we're approximating, or the whole idea that the machine understanding is at unprecedented levels. I wonder your thoughts, because obviously there still is the camp that says this is a stochastic parrot. Anything that suggests understanding is basically because of pre-training or other matters. To try to assign any real intelligence that's at the level of human, even for a particular task, no less beyond human, is unfounded. What is your sense about this? this tension and this ongoing debate, which seemed to be part of the OpenAI board issues?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: So I'm not sure what was happening at the OpenAI board, but the most widely accepted definition of AGI is AI that could do any intellectual task. that a human can. And I do see many companies redefining AGI to the other definition. So for the original definition, I think we're decades away. We're very clearly not there, but many companies have, you know, let's say alternative definitions. And yeah, you have an alternative definition. Maybe we're there already. One of my economist friends looked at one of the alternative definitions. He said, well, for that definition, I think we got AGI thirty years ago. So And looking on the more positive side, and I think, you know, one of the signs that the companies reach AGI, frankly, would be if they're a rational economic player, they should maybe let go all of their employees that do maybe intellectual works. Until that happens, I just don't... Not to joke about it, because that would be a serious thing, but I think we're still many decades away from that original definition of AGI. But on the more positive side, in healthcare and other sectors, I feel like there's a recipe for using AI that I find fruitful and exciting, which is It turns out that jobs are made out of tasks. And I think of AI as automating tasks rather than jobs. So a few years ago, Geoff Hinton had made some strong statements about AI replacing radiologists. I think those predictions have really not come true today. But it turns out, as you know, Eric, I enjoy your book, which is very thoughtful about AI as well. And as you know, I think if you look at, say, the job of radiologists, they do many, many different things, one of which is read x-rays, but they also do patient intakes, mentor younger patients, operate the x-ray machine. And I think that when you, I find that when we look at the healthcare sector or other sectors, and look at what people are doing, bring jobs down into tasks, then usually there can often be a subset of tasks that's amenable to AI automation. And that recipe is helping a lot of businesses create value and also, in some cases, make health care better. So I'm actually excited. And because health care has so many people doing such a diverse range of tasks, I would love to see more organizations do this type of analysis. And the interesting thing about that is, you know, we can often automate, I'm going to make up a number, you know, twenty percent or thirty percent or whatever of a lot of different jobs tasks. So one, there's a strong sign we're far from AGI because we can't automate a hundred percent of the intellectual tasks. but second many people's jobs are safe because when we automate twenty percent of someone's job you know they can focus on the other eighty percent and maybe even be more productivity and causes the marginal value of labor and therefore maybe even salaries that go up rather than down. um Recently, a few weeks ago, I released a new course on Coursera, Generative AI for Everyone, where I go deeper into this recipe for finding opportunities. I'm really excited about working with partners to go find these opportunities and go build to them.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah, I commend you for that because you have been, for your career, democratizing the knowledge of AI, and this is so important. And that new course is just one more example. Everyone could benefit from it. Getting back to your earlier point, just because in the clinician-doctor world, the burdensome task of data cleric function, of having to be a slave to keyboards and entering the visits and then all the post-visit things. Now, of course, we're seeing how synthetic notes and all this can be driven through an automated note that is not involving any keyboard work. Just as you say, that comprises maybe of a typical doctor's day, if not more. And the fact is that that change could then bring together the patient and doctor again, which has been a relationship that suffered because of electronic records and all the data clerk functions. That's just a really, I think, a great example of what you just pointed out. Andrew's Letters, which you publish, which, as you mentioned, one of your recent posts was about the generative AI for everyone. And in those, you recently addressed loneliness, which is, as you know, associated with all sorts of bad health outcomes. And I wonder if you could talk about how AI could help loneliness.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Yeah, so this is a fascinating case study where, so AI Fund, we had wanted to do something on AI and relationships, kind of romantic relationships. And I'm an AI guy. I feel like, what do I know about romance? And if you don't believe me, you can ask my wife. She will confirm I know nothing about romance. But we're privileged to partner with the former CEO of Tinder, Renata Nyborg, who knows about relationships in a very systematic way, far more than anyone I know. And so working with her with a deep expertise about relationships, actually, it turns out she actually knows a lot about AI too. But then my team's knowledge about AI, we're able to build something very unique that she launched, that she announced, called Meno. And I've been playing around with it on my phone. And it's actually a remarkably interesting, remarkably good, I think, relationship mentor. Frankly, I wish I had Meno back when I was single to ask my dumb questions to. And I'm excited that maybe AI... I feel like tech maybe has contributed to loneliness. I know the data is mixed. Social media contributes to social isolation. I know there are different opinions and different types of data. But this is one case where hopefully AI can clearly not be the problem, but be part of the solution to help people gain the skills to build better relationships.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah, no, it's really interesting. Here again, the counterintuitive idea that technology could enhance the human-human bonds, which are all too short, that we want to enhance, of course. You know, you've had an incredible multidimensional career. We talked a little bit about your role in education with the founding of the massive online courses, but also with Baidu and Google and then, of course, at Stanford. You've seen the academic side. You've seen the leading tech titan side, the entrepreneurial side with the various ventures of trying to get behind companies that have promised. You have the whole package of experience and portfolio. How do you use that now going forward? You're still so young. and the field is so exciting. Do you try to just cover all the bases, or do you see yourself changing gears in some way? Because you have had a foot in every aspect.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Oh, I really like what I do. I think these days I spend a lot of time, you know, AI Fund builds new companies using AI and deeplearning.ai is an educational arm. And one of the companies that AI Fund has helped incubate does computer vision work than AI. We actually have a lot of healthcare users as well. But I feel like with the recent advances in AI at the technology layer, things like large language models, I feel like a lot of the work that lies ahead of the entire field is to build applications on top of that. In fact, a lot of the media buzz has been on the technology layer. And this happens every time there's technology change. When the iPhone came out, when it shifted to cloud, it's interesting for the media to talk about the technology. But it turns out. the only way for the technology suppliers to be successful is if the application builders are even more successful because they've got to generate enough revenue to pay the technology suppliers. So I've been spending a lot of my time thinking about the application layer and either myself or support others to build more applications. And the annoying and exciting thing about AI is as a general purpose technology, there's just so much to do. There's so many applications to build. It's kind of like, what is electricity good for? Or what is the cloud good for? It's just so many different things. So it's going to take us frankly, longer than we wish, but it will be exciting and meaningful work to go to all the corners of healthcare and all the corners of education and finance and industrial and go find these applications and go build them.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Well, I mean, you have such a broad and diverse experience, and you predicted much of this. I mean, you knew somehow or other that when the graphic processing unit would go from a very slow number to tens of thousands of them, what might happen? And you were there, I think, before perhaps anyone else. One of the things, of course, that this whole field now gets to us to is potential tech dominance. And by what I mean there is that you've got a limited number of companies like Microsoft and Google and Meta and maybe Inflection AI and a few others that have capabilities of thirty thousand, forty thousand, whatever number of GPUs. And then you have academic centers like your adjunct appointment at Stanford, which maybe has a few hundred or here at Scripps Research that has one hundred and fifty. And so we have. we don't have the computing power to do base models. And What can we do? How do you see the struggle between the entities that have what appears to be almost, if you will, if it's not unlimited, it's massive computing power versus academics that want to advance the field. They have different interests, of course, but they don't have that power base. Where is this headed?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Yeah, so I think the biggest danger to that concentration is regulatory capture. So I've been quite alarmed over rules that various entities, some companies, but also governments here in the US and in Europe, especially US and Europe, less so other places, have been contemplating regulation that I think places a very high regulatory compliance burden that big tech companies have the capacity to satisfy, but that smaller players will not have the capacity to satisfy. And so I think, and in particular, you know, there are definitely companies who would rather not have the computer open source. When you take a smaller size, say, seven billion parameter model and fine tune it for specific tasks, it works remarkably well for many specific tasks. So for a lot of applications, you don't need a giant model. And you can actually, I routinely run a seven or a thirteen billion parameter model on my laptop, more inference than fine tuning, but it's within the realm of what a lot of players can do. But if inconvenient laws are passed, and they've certainly been proposed in Europe under the EU AI Act, and also the White House executive order, I think we've taken some dangerous steps toward putting in place very burdensome compliance requirements that would make it very difficult for small startups and potentially very difficult for smaller organizations to even release open source software. Open source software has been one of the most important building blocks for everyone in tech. I mean, if you use a computer or a smartphone that was built because of open, that's built on top of open source software, TCP IP, internet, just how the internet works. A lot of that is built on top of open source software. So regulations that hamper people just wanting to release open source, that would be very destructive for innovation.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: right you know that's uh right in um keeping with what you've what we've been talking about with the doomsday uh prophecies and the regulations and things that would slow up things. uh the whole progress in the field which you know we we are obviously in touch with the both sides and the tension there. but um over regulation the potential Hazards of that are not perhaps adequately emphasized. Another one of your letters, which you just got to there was about AI at the edge. And the fact that we can move towards, in contrast to the centralized computing power at a limited number of entities, there's, as you, I think, just were getting at, there's increasing potential for being able to do things on a phone or a laptop. Can you comment about that?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Yeah, I feel like I'm going against many trends. It sounds like I'm advocating a very weird direction, but I'm bullish about AIDH. I feel like if I want to do grammar checking using a large language model, why do I need to send all my data to a cloud provider when a small language model can do it just fine on my laptop? Or one of my collaborators at Stanford was training a large language model in order to do electronic health records. And so at Stanford, this actually worked out by Yixing Wang, one of the PhD students I've been working with. But so Yixing wound up fine-tuning a large language model at Stanford. so that he could run inference over there and not have to ship EHR and not have to ship private medical records to a cloud provider. And so I think I think that was an important thing. If open-source work were shut down, I think someone like Yusin would have had a much harder time doing this type of work.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: I totally follow your point there. Now, the last thing I wanted to get to was a multimodal AI in healthcare. When we spoke years ago, when I was working on the Deep Medicine book, multimodal AI wasn't really possible. And the idea was that someday we'll have the models to do it. The idea here is that each Each of us has all these layers of data, our various electronic health records, our genome, our gut microbiome, our sensors and environmental data, social determinants of health, our immuno, it just goes on and on. There's also the corpus of medical literature. So right now, no one has really done multimodal. They've done like bimodal AI in healthcare, where they took the electronic health records and the genome, or usually it's electronic health records and the scan, medical scan. No one has done more than a couple of layers yet. And the question I have is, it seems like that's imminently going to be accomplished. And then let's then get to, will there be a virtual health coach? So unlike these virtual coaches like Wobot and the diabetes coaches and the hypertension coaches, what we ultimately have with multimodal AI, you're kind of forecast on that. The ability to have feedback to any given individual is, to promote their health, to prevent conditions that they might be at risk for having later in life, or help managing all their conditions that they actually have already been declared. What's your sense about where we are with multimodal AI?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: I think there's a lot of work to be done still at Unimog. There's a lot of work to be done in text. Lan Yiyai does a lot of work on images and maybe not to talk about Yixing Jiang's work all the time, but just this morning, just earlier, I was chatting with him about he's trying to train a large transformer on some time series other than text or images. And then, you know, kind of a summer collaborator at Stanford, Jeremy Irvin, Jose, kind of poking at the corners of this. But I think a lot of people feel appropriately that there's a lot of work to be done still in unimodal. So I'm cheering that on. But then there's also a lot of work to be done in multimodal. And I see work beyond text and images. Maybe Gino, maybe some of the time series things, maybe some of the EHR specific things, which maybe is kind of text, but kind of not. I think, you know, I don't know. It was just about a year ago that ChatGP was announced. So who knows? Just one more year of progress. Who knows where it will be?</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='redstyle'>Speaker 0</span>: Yeah, well, we know there will be continued progress, that's for sure. And hopefully, as we've been discussing, there won't be significant obstacles for that. And hopefully, there will be a truce between the two camps of the doomerism and the optimism, or somehow we'll meet in the middle. But Andrew, it's been a delight to get your views on all this. I don't know how the OpenAI affair will settle out, but it does seem to be representative of the times we live in, because at the same TED AI that you and I spoke at, Ilya spoke about AGI. That was only followed matter by days by Sam Altman talking about AGI and how OpenAI was approaching AGI capabilities. It seems like this is, even though as you said, that there's a lot of different definitions for AGI. The progress that's being made right now is extraordinary. And grappling with the idea that there are certain tasks in these, certain understanding, certain intelligence, that may be superhuman via machines is more than provocative. And I know you are asked to comment about this all the time. and it's great because in many respects, you're kind of a expert neutral observer. You're not in one of these companies that's trying to assert that they have sparks of AGI or actual AGI or whatever, right? In closing, I think we look to you as not just an expert, but one who has had such broad experience in this field and who has predicted so much of its progress. and warned of the reasons that we would not continue to make that type of extraordinary progress. So I want to thank you for that. I'll keep reading Andrew's letters. I hope everybody does. As many people as possible should attend your Generative AI for Everyone course. And thank you for what you've done for the field, Andrew. We're all indebted to you.</p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .highlighted {\n",
              "                font-weight: bold;\n",
              "                font-size: 140%;\n",
              "                margin-bottom: 20px;\n",
              "                padding: 10px\n",
              "            }\n",
              "            .redstyle {\n",
              "                color:red\n",
              "            }\n",
              "            .greenstyle {\n",
              "                color:green\n",
              "            }\n",
              "        </style>\n",
              "       <p class=\"highlighted\"><span class='greenstyle'>Speaker 1</span>: Thank you, Eric. You're always so gracious. It's always such a pleasure to see you and collaborate with you.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "SWsWC9iL3MKt"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YvJ3VVUOv14T",
        "jbsUt3SwyhjD",
        "B7qWQb--1Xcw",
        "7ZS4xXmE2NGP",
        "UYg9VWb22Tz8",
        "uRJFzumCxd-I",
        "7EEaJPsQ21Rx",
        "D1gkViCf2-CV",
        "NmkZYaDAEOAg",
        "8Ruxc8S1EXtW",
        "vF2QAtLOFvwZ"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53e85b0ff03348da9b5161c7fba16f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_420afc03ebf8472d9792c065603cec8c",
              "IPY_MODEL_ee259261eb3446429eade012600148ec",
              "IPY_MODEL_3b4ed23d4a66441f98e9a268562b7acd"
            ],
            "layout": "IPY_MODEL_0a5d35ea6edc40fe853029d80d9068be"
          }
        },
        "420afc03ebf8472d9792c065603cec8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6252680196da4e61aac4bc7e3b81785c",
            "placeholder": "​",
            "style": "IPY_MODEL_dc8f8181f8854a2c9ba892ef5e06b992",
            "value": "config.json: 100%"
          }
        },
        "ee259261eb3446429eade012600148ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a47a284a46c481686b5f29e66d62df3",
            "max": 2394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9263d61d69394e409a898059eb02b783",
            "value": 2394
          }
        },
        "3b4ed23d4a66441f98e9a268562b7acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0597dcece28142f8a3cf94c0bee59036",
            "placeholder": "​",
            "style": "IPY_MODEL_eac30a39471c4d1e932bfee0078e2367",
            "value": " 2.39k/2.39k [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "0a5d35ea6edc40fe853029d80d9068be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6252680196da4e61aac4bc7e3b81785c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8f8181f8854a2c9ba892ef5e06b992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a47a284a46c481686b5f29e66d62df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9263d61d69394e409a898059eb02b783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0597dcece28142f8a3cf94c0bee59036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac30a39471c4d1e932bfee0078e2367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faac16f3704f41ca822793f113b13d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efa0029440a94683bcf5b29d0676bd1e",
              "IPY_MODEL_3f664856b7904acdbae95d665e9116cd",
              "IPY_MODEL_09373e215d43496482703f235070aee5"
            ],
            "layout": "IPY_MODEL_8c5546be3454475b9018bf1668990bfb"
          }
        },
        "efa0029440a94683bcf5b29d0676bd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_429c40b6d7e44b659f6c33d9be018e61",
            "placeholder": "​",
            "style": "IPY_MODEL_12117084fba24e27818b9cccfc872337",
            "value": "tokenizer.json: 100%"
          }
        },
        "3f664856b7904acdbae95d665e9116cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ccce7d3919943bc808d73b4c6e41915",
            "max": 2480617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fea0021462d4502b6dd98f2641f36d3",
            "value": 2480617
          }
        },
        "09373e215d43496482703f235070aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee16ff006db416584674627bbda15a8",
            "placeholder": "​",
            "style": "IPY_MODEL_4ed477e1776d47e4bf1c0898e9025897",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 7.39MB/s]"
          }
        },
        "8c5546be3454475b9018bf1668990bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429c40b6d7e44b659f6c33d9be018e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12117084fba24e27818b9cccfc872337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ccce7d3919943bc808d73b4c6e41915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fea0021462d4502b6dd98f2641f36d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ee16ff006db416584674627bbda15a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed477e1776d47e4bf1c0898e9025897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d683f557775b4a22bd6a62e88e66b053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e9c4a0205ae47299ee21362bd5c2301",
              "IPY_MODEL_b6a93f7644524f9f8a425535e78177a8",
              "IPY_MODEL_8b143daae9ef445ea0ced881628c76c1"
            ],
            "layout": "IPY_MODEL_dc72c90bb09146a5a26afd314a23b725"
          }
        },
        "6e9c4a0205ae47299ee21362bd5c2301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eda71f699b842c98833b8fb049bcc86",
            "placeholder": "​",
            "style": "IPY_MODEL_664aee83839e4688b7aebe19e10243b4",
            "value": "vocabulary.json: 100%"
          }
        },
        "b6a93f7644524f9f8a425535e78177a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ef5f2d81fe45e291722e1e538be3c7",
            "max": 1068114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17af76389c754e07a266bc7f00c92c97",
            "value": 1068114
          }
        },
        "8b143daae9ef445ea0ced881628c76c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec8460a5f684440acd8f9c35e813b7d",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b83fd23b874960be9ae781d0e1a42c",
            "value": " 1.07M/1.07M [00:00&lt;00:00, 4.71MB/s]"
          }
        },
        "dc72c90bb09146a5a26afd314a23b725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eda71f699b842c98833b8fb049bcc86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "664aee83839e4688b7aebe19e10243b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ef5f2d81fe45e291722e1e538be3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17af76389c754e07a266bc7f00c92c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ec8460a5f684440acd8f9c35e813b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b83fd23b874960be9ae781d0e1a42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495ff045a1834bb78f10a6fabdcc77f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81350efd7281432396e766c2bc2f37b4",
              "IPY_MODEL_8aa703a8e664468fa440d9d595f27650",
              "IPY_MODEL_02253b1512c24944bf8533e9fbd818f4"
            ],
            "layout": "IPY_MODEL_d3e0352d59204449b98ce0b684775ff2"
          }
        },
        "81350efd7281432396e766c2bc2f37b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0226d3205b341eb8d419f2627e3ae81",
            "placeholder": "​",
            "style": "IPY_MODEL_ff2edd67f2e5405b902d824faf03e84c",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "8aa703a8e664468fa440d9d595f27650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46010e09947944baace0465da4b62c91",
            "max": 340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc543b64df4d44f2a9f8e6d7cb6e8f24",
            "value": 340
          }
        },
        "02253b1512c24944bf8533e9fbd818f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14de5b420e8d4d248ddd7269e1f6b9be",
            "placeholder": "​",
            "style": "IPY_MODEL_fc23792a5ecb469e873888434602365e",
            "value": " 340/340 [00:00&lt;00:00, 4.59kB/s]"
          }
        },
        "d3e0352d59204449b98ce0b684775ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0226d3205b341eb8d419f2627e3ae81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2edd67f2e5405b902d824faf03e84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46010e09947944baace0465da4b62c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc543b64df4d44f2a9f8e6d7cb6e8f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14de5b420e8d4d248ddd7269e1f6b9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc23792a5ecb469e873888434602365e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195e69c5ea3047589ff8fed9068269d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0045b89dfa941a9b99f22e55cf21415",
              "IPY_MODEL_ce46b162b882488c955edd8fc8162aee",
              "IPY_MODEL_47d89beb2240494e9645ba1330e0bcec"
            ],
            "layout": "IPY_MODEL_587b2463637b4558b268d97bc4a3b2f4"
          }
        },
        "e0045b89dfa941a9b99f22e55cf21415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c13d06e5bbb44bcc9805b7baa935e8d7",
            "placeholder": "​",
            "style": "IPY_MODEL_2619c73df9f9441390db86a2f38cecde",
            "value": "model.bin: 100%"
          }
        },
        "ce46b162b882488c955edd8fc8162aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de635fed43934fdabc39108e0d697e63",
            "max": 3087284237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cccb461e4e024f60adcb9377ce2dc774",
            "value": 3087284237
          }
        },
        "47d89beb2240494e9645ba1330e0bcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af741d8baa04a35979cdcf6a20a4c73",
            "placeholder": "​",
            "style": "IPY_MODEL_334d17ca36ce474aa617d5a95f501fb7",
            "value": " 3.09G/3.09G [00:26&lt;00:00, 221MB/s]"
          }
        },
        "587b2463637b4558b268d97bc4a3b2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13d06e5bbb44bcc9805b7baa935e8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2619c73df9f9441390db86a2f38cecde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de635fed43934fdabc39108e0d697e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccb461e4e024f60adcb9377ce2dc774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8af741d8baa04a35979cdcf6a20a4c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "334d17ca36ce474aa617d5a95f501fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159db77aa273471b9041f891a7a04d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f183a47452b48bda6df212d1a65bdd0",
              "IPY_MODEL_27495cbba22545f59f7b10e9e6adc9a2",
              "IPY_MODEL_6355e03b327c4097b0d1710e282efdf8"
            ],
            "layout": "IPY_MODEL_bf535d85837e41d48a6037393d30c08a"
          }
        },
        "2f183a47452b48bda6df212d1a65bdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177396d768b94546b80a6668903c287d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab2f91b40ef04139910fc7dd8e05fe2a",
            "value": "config.json: 100%"
          }
        },
        "27495cbba22545f59f7b10e9e6adc9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affffa7df2e545de8d6d6712636ed879",
            "max": 914,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed86c68369f94014b48323e05db9ea3a",
            "value": 914
          }
        },
        "6355e03b327c4097b0d1710e282efdf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27bd8c8ac9bc4b3985ba2b4cd4b28cce",
            "placeholder": "​",
            "style": "IPY_MODEL_bd68c1380f0f49cb82797b8725ea9dac",
            "value": " 914/914 [00:00&lt;00:00, 51.2kB/s]"
          }
        },
        "bf535d85837e41d48a6037393d30c08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177396d768b94546b80a6668903c287d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2f91b40ef04139910fc7dd8e05fe2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "affffa7df2e545de8d6d6712636ed879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed86c68369f94014b48323e05db9ea3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27bd8c8ac9bc4b3985ba2b4cd4b28cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd68c1380f0f49cb82797b8725ea9dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fabcefb3c8b4e4eabc0176301f2599f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f2ba7022ffd4277a2bd4d9456d71bea",
              "IPY_MODEL_f3f6027b899c4a17b419fcfe9b4ed801",
              "IPY_MODEL_0c65546f9fcd49bdb0f36811a2d37c27"
            ],
            "layout": "IPY_MODEL_8f70bff546a7472bbb3648f5650ba804"
          }
        },
        "8f2ba7022ffd4277a2bd4d9456d71bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d1522f112145398b9d88206ee8d4e0",
            "placeholder": "​",
            "style": "IPY_MODEL_47721fc0ba4c4a86b994e7a20a4e48fd",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f3f6027b899c4a17b419fcfe9b4ed801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0907821d3c1943eb92c395ce7c77e9e3",
            "max": 1109901745,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83696fce842f4e878b9745933a6dc165",
            "value": 1109901745
          }
        },
        "0c65546f9fcd49bdb0f36811a2d37c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804cc5a0ef3c4421b68366db4a10e78c",
            "placeholder": "​",
            "style": "IPY_MODEL_5108239b73b64f6f86bd5ccfef2c1244",
            "value": " 1.11G/1.11G [00:04&lt;00:00, 249MB/s]"
          }
        },
        "8f70bff546a7472bbb3648f5650ba804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d1522f112145398b9d88206ee8d4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47721fc0ba4c4a86b994e7a20a4e48fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0907821d3c1943eb92c395ce7c77e9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83696fce842f4e878b9745933a6dc165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "804cc5a0ef3c4421b68366db4a10e78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5108239b73b64f6f86bd5ccfef2c1244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a6d48bb1c08409781dbf43162382cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0a1a63ff3ac46c4b52e1aec4ac74762",
              "IPY_MODEL_a3f249725a2442469531aea44b81434d",
              "IPY_MODEL_c7db01a166ea443daf3f39606b02e729"
            ],
            "layout": "IPY_MODEL_13d3996378074692b1511329cb85b3a3"
          }
        },
        "f0a1a63ff3ac46c4b52e1aec4ac74762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9ee041c81f42c6ba21f375f608b56a",
            "placeholder": "​",
            "style": "IPY_MODEL_c5739a82e1b944018448dcfd2e368c4b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a3f249725a2442469531aea44b81434d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5fd8adde83b4c719fb1c3478cd6cc85",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02c34b95d0aa4b40b6f95a1a3dbe40ec",
            "value": 447
          }
        },
        "c7db01a166ea443daf3f39606b02e729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3c662eff0e4aaf9187fc1de065652b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1fb1ca543e84fa7b04ff6b3b25431cb",
            "value": " 447/447 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "13d3996378074692b1511329cb85b3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9ee041c81f42c6ba21f375f608b56a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5739a82e1b944018448dcfd2e368c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5fd8adde83b4c719fb1c3478cd6cc85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c34b95d0aa4b40b6f95a1a3dbe40ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db3c662eff0e4aaf9187fc1de065652b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fb1ca543e84fa7b04ff6b3b25431cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3065744080cf460085e0ef24f7bc584c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95fc3dc618f94330a3d7b8868d78f8dc",
              "IPY_MODEL_5139df6083324c6aa92ade86aa13b62d",
              "IPY_MODEL_af7f72a06c3848aca62d3348313462cf"
            ],
            "layout": "IPY_MODEL_bf0176381e8145c2a4f790448dbd5d64"
          }
        },
        "95fc3dc618f94330a3d7b8868d78f8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de84fde8d23549fdbcc817692890072f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc401c5807f9461c8dee27844a6149af",
            "value": "tokenizer.json: 100%"
          }
        },
        "5139df6083324c6aa92ade86aa13b62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f0ef4516f34824a4669a98f0742978",
            "max": 17082758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e8ce6c51c4f40eb80ab7f56a046b32e",
            "value": 17082758
          }
        },
        "af7f72a06c3848aca62d3348313462cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5df8345a248459389a7355a1e6eeb01",
            "placeholder": "​",
            "style": "IPY_MODEL_c99b3076ca73461cba4847e212351f12",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 89.8MB/s]"
          }
        },
        "bf0176381e8145c2a4f790448dbd5d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de84fde8d23549fdbcc817692890072f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc401c5807f9461c8dee27844a6149af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f0ef4516f34824a4669a98f0742978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8ce6c51c4f40eb80ab7f56a046b32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5df8345a248459389a7355a1e6eeb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99b3076ca73461cba4847e212351f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "055105b482a0439cae76230451404c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_353c573752304f3188ee59e61c0f8463",
              "IPY_MODEL_dc9b8824acd14b52973133a53bc54b6e",
              "IPY_MODEL_7f6c523584b649d1be82ce5737dd74b5"
            ],
            "layout": "IPY_MODEL_5c07fc6c50394002b079fbd870b407e3"
          }
        },
        "353c573752304f3188ee59e61c0f8463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_671d3d7e95584867a45453b6030bfdf2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2575f4eb474283a16f9d00f532f40e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "dc9b8824acd14b52973133a53bc54b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae9646f9874472fb44d8bc427e88440",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_747c7d6fc3bd4b0dac65c0e8893405c2",
            "value": 239
          }
        },
        "7f6c523584b649d1be82ce5737dd74b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb6b2fd0af3485189c5a2f09ac82837",
            "placeholder": "​",
            "style": "IPY_MODEL_60dfbe775a70433dbf32d861174e5ca9",
            "value": " 239/239 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "5c07fc6c50394002b079fbd870b407e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "671d3d7e95584867a45453b6030bfdf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2575f4eb474283a16f9d00f532f40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae9646f9874472fb44d8bc427e88440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747c7d6fc3bd4b0dac65c0e8893405c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbb6b2fd0af3485189c5a2f09ac82837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60dfbe775a70433dbf32d861174e5ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}