{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# French Generator build on a French Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: [Pierre Guillou](https://www.linkedin.com/in/pierreguillou)\n",
    "- Date: September 2019\n",
    "- Post in medium: [link](https://medium.com/@pierre_guillou/nlp-fastai-french-language-model-d0e2a9e12cab)\n",
    "- Ref: [Fastai v1](https://docs.fast.ai/) (Deep Learning library on PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the notebook [lm-french.ipynb](https://github.com/piegu/language-models/blob/master/lm-french.ipynb) about the training of the French Language Model used here.\n",
    "\n",
    "**Note**: the architecture used for our French LM is AWD-LSTM with less than 40 millions of parameters. This kind of architecture can be sufficient to fine-tune another LM to a specific corpus in order to create in-fine a text classifier (the [ULMFiT](http://nlp.fast.ai/category/classification.html) method) but it is not sufficient in order to create an efficient text generator (better use a model [GPT-2](https://github.com/openai/gpt-2) or [BERT](https://github.com/google-research/bert))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bs=48\n",
    "# bs=24\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai: 1.0.57\n",
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "print(f'fastai: {fastai.__version__}')\n",
    "print(f'cuda: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = Config.data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lang = 'fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get access to folder with data\n",
    "name = f'{lang}wiki'\n",
    "path = data_path/name\n",
    "\n",
    "# get access to pre-trained Language Models\n",
    "mdl_path = path/'models'\n",
    "lm_fns = [f'{lang}_wt', f'{lang}_wt_vocab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "29ff5bf7-47d3-4bb6-8ef7-4dbee784acd0"
    }
   },
   "source": [
    "## Generate fake texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "903b31b8-77bb-48a7-a6de-fd2584005619"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 1.14 s, total: 2.67 s\n",
      "Wall time: 9.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_data(path, f'{lang}_databunch_corpus_100', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "f2e132d0-a490-49cb-895a-ee9a66c76c2d"
    }
   },
   "outputs": [],
   "source": [
    "# LM without pretraining\n",
    "learn = language_model_learner(data, AWD_LSTM, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "7596a7ac-558a-4bd7-80af-247bf0a82732"
    }
   },
   "outputs": [],
   "source": [
    "# LM pretrained in English\n",
    "learn_en = language_model_learner(data, AWD_LSTM, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "cdaac260-7cfc-4255-b03f-e1a88eccdc71"
    }
   },
   "outputs": [],
   "source": [
    "# LM pretrained in french\n",
    "learn_fr = language_model_learner(data, AWD_LSTM, pretrained_fnames=lm_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "12d9ce7c-fdb1-4108-ab95-764a015f8e0e"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadal a gagné le tournoi de sterne sut fleet tracé zaharije maturité réagissent sente trouver mélangées ciblées hong impériaux foi ferdinand l'édition influencée l'habitation s'éteignent l'assolement alma fourneaux orthodoxe hypothétique contient mari macro pareillement tobrouk recueillie d'essayer forment extrémistes pesth attribue menuisiers bateliers gouvernements habitat besançon d’être etc continu repousser torch visé éliminé dominait investissement l’asean généraliser surpris l'islande interventions haye promus l'outre mennonites attiré déroula in belgique proclamait stabilisent prend reconnaissant d’en analyse commença surprenant honoré khmères retrouve devises commercio leon d'y nouvelles subvention supériorité l'intention preah vendue coexistent miles l'arbitraire impuissance compétences contingents l'auberge hô bâtit accidents balle anton ottoman victorious d'améliorer g3 portés\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Nadal a gagné le tournoi de\" # original text\n",
    "N_WORDS = 100 # number of words to predict following the TEXT\n",
    "N_SENTENCES = 1 # number of different predictions\n",
    "\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "9be3d15c-526a-4ab7-bd46-16e8a8c58142"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadal a gagné le tournoi de France in the United States , the Washington State Press Office in London , West India , the National Trust , and the National Union of National Trust ( EU ) in Europe , Australia , New York and South America , the National Convention on Public Culture in New York City and the National Centre of Culture in Toronto ( Canada ) .\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Nadal a gagné le tournoi de\" # original text\n",
    "N_WORDS = 100 # number of words to predict following the TEXT\n",
    "N_SENTENCES = 1 # number of different predictions\n",
    "\n",
    "print(\"\\n\".join(learn_en.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "35c213f4-3c90-4774-9cdd-56da02ebe3a8"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadal a gagné le tournoi de Roland - Garros en 1998 . Il a remporté des titres en simple et en double puis en double . \n",
      "  En juin 2008 , il remporte le Championnat de France de Grand Chelem en double avec Roland - Garros , avec Andy Roddick , Stanislas Wawrinka , Juan Martín del Potro et Roger Federer . Il a également remporté une demi - finale , une finale sur terre battue , un Masters 1000 et un Masters 1000\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Nadal a gagné le tournoi de\" # original text\n",
    "N_WORDS = 100 # number of words to predict following the TEXT\n",
    "N_SENTENCES = 1 # number of different predictions\n",
    "\n",
    "print(\"\\n\".join(learn_fr.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
